{
  "hash": "8cb90a60dcdf28eb62bc59959a3e55bf",
  "result": {
    "markdown": "---\ntitle: \"R You Ready? An I/O Psychologist's Guide to R & Rstudio\"\ndescription: \"My January 16, 2024 METRO workshop is now a blog post, covering the essential 20% of R syntax for 80% of data analysis tasks. This blog post is designed for both R beginners and those seeking a refresher.\"\ndate: 1-15-2024\ncategories: [R, Workshop]\ncitation: \n  url: https://sijan14.github.io/sijan_portfolio/posts/2024-12-31-R-Workshop/ \nimage: computer.jpg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\n## 🌟 Introduction\n\nIn recent years, the R programming language emerged as the industry standard in social science research, owing to its robust statistical analysis tools, powerful data visualization capabilities, and a rich ecosystem of packages. Its open-source nature and emphasis on reproducibility further propelled its widespread adoption. This workshop, titled “R You Ready? An I/O Psychologist’s Guide to R and RStudio,\" was tailored for both R novices and those seeking a refresher, focusing on the essential 20% of R syntax that facilitated 80% of data analysis tasks. Participants were introduced to the RStudio environment and fundamental R syntax, followed by hands-on sessions covering data transformation (dplyr), data visualization (ggplot2), statistical analyses (lm, stats), APA-style reporting (markdown, apa, papaja), and text mining (stringr, tidytext). The workshop concluded with collaborative problem-solving sessions to reinforce the concepts learned. The aim was to introduce students and practitioners to the power of R to carry out basic and advanced analyses, along with the capability to visualize and report findings.\n\n::: {style=\"display: flex; justify-content: center; align-items: center; height: 100vh;\"}\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/3awJKhGM3H8Dbw?hostedIn=slideshare&amp;page=upload\" width=\"800\" height=\"600\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## 🧹 Tutorial #1 (Cleaning)\n\n\n\n\n\n### Getting Started\n\nBefore diving into the transformations, let’s load the necessary package and dataset. You can download the [dataset](https://drive.google.com/file/d/1zUQf6jiZq7vq1GzktL0lIo__uaVj7Vhr/view?usp=sharing) to follow along.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Uncomment the next four lines if you haven't installed the package\n# install.packages(\"tidyverse\")\n# install.packages(\"psych\")\n# install.packages(\"lsr\")\n# install.packages(\"apaTables\")\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(lsr)\nlibrary(apaTables)\n\n# Loading the dataset\ndf <- read_csv(\"IBM HR Data.csv\")\n\n# Checking all the column names\nnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Age\"                      \"Attrition\"               \n [3] \"BusinessTravel\"           \"DailyRate\"               \n [5] \"Department\"               \"DistanceFromHome\"        \n [7] \"Education\"                \"EducationField\"          \n [9] \"EmployeeCount\"            \"EmployeeNumber\"          \n[11] \"Application ID\"           \"EnvironmentSatisfaction\" \n[13] \"Gender\"                   \"HourlyRate\"              \n[15] \"JobInvolvement\"           \"JobLevel\"                \n[17] \"JobRole\"                  \"JobSatisfaction\"         \n[19] \"MaritalStatus\"            \"MonthlyIncome\"           \n[21] \"MonthlyRate\"              \"NumCompaniesWorked\"      \n[23] \"Over18\"                   \"OverTime\"                \n[25] \"PercentSalaryHike\"        \"PerformanceRating\"       \n[27] \"RelationshipSatisfaction\" \"StandardHours\"           \n[29] \"StockOptionLevel\"         \"TotalWorkingYears\"       \n[31] \"TrainingTimesLastYear\"    \"WorkLifeBalance\"         \n[33] \"YearsAtCompany\"           \"YearsInCurrentRole\"      \n[35] \"YearsSinceLastPromotion\"  \"YearsWithCurrManager\"    \n[37] \"Employee Source\"         \n```\n:::\n:::\n\n\n<br>\n\n### Sorting Data\n\nSorting is often one of the first transformations you’ll perform. Here’s how to do it in base R and tidyverse.\n\n##### Option 1: Base R\n\nIn base R, you can use the `order()` function to sort by one or more columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by age in ascending order\nindex <- order(df$Age) \ndf <- df[index, ]\n```\n:::\n\n\n##### Option 2: Tidyverse\n\nThe `arrange()` function from dplyr is a more concise and readable option:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sort by multiple columns: Age (descending) and DailyRate (ascending)\ndf <- arrange(df, desc(Age), DailyRate)\n```\n:::\n\n\n<br>\n\n### Renaming Columns\n\nRenaming columns is another frequent task, especially when preparing data for analysis or visualization.\n\n##### Option 1: Base R\n\nUse the `colnames()` function to rename specific columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rename the first column (age)\ncolnames(df)[1] <- \"how_old\"\n```\n:::\n\n\n##### Option 2: Tidyverse\n\nThe `rename()` function provides an intuitive way to rename columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rename \"how_old\" back to \"age\"\ndf <- rename(df, \"age\" = \"how_old\")\n```\n:::\n\n\n<br>\n\n### Filtering Data\n\nFiltering rows based on specific conditions is crucial for focusing your analysis. Let’s filter for single employees earning over \\$10,000 per month:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter rows where MaritalStatus is \"Single\" and MonthlyIncome > 10000\nsingle_rich <- df %>%\n  filter(MaritalStatus == \"Single\", MonthlyIncome > 10000)\n```\n:::\n\n\nThe pipe operator (`%>%`) from the tidyverse makes it easy to chain multiple operations.\n\n<br>\n\n### Summarizing Data\n\nSummarization provides insights into key metrics like mean and standard deviation. Here’s how to summarize the filtered data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# summarizing the subset data\nsingle_rich %>%\n  summarise(Mean = mean(MonthlyIncome), SD = sd(MonthlyIncome))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n    Mean    SD\n   <dbl> <dbl>\n1 15043. 3200.\n```\n:::\n:::\n\n\nThis calculates the average (Mean) and standard deviation (SD) of the MonthlyIncome column for the filtered subset.\n\n<br>\n\n### Subsetting Columns\n\nSelecting specific columns is often necessary to focus on relevant data or remove unnecessary variables. You can use the `select()` function from the **tidyverse** to keep only the desired columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep specific columns\ndf %>%\n  select(Attrition, DailyRate, Department, Education)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 23,532 × 4\n   Attrition        DailyRate Department             Education\n   <chr>                <dbl> <chr>                      <dbl>\n 1 Current employee       370 Research & Development         4\n 2 Current employee       370 Research & Development         4\n 3 Current employee       370 Research & Development         4\n 4 Current employee       370 Research & Development         4\n 5 Current employee       370 Research & Development         4\n 6 Current employee       370 Research & Development         4\n 7 Current employee       370 Research & Development         4\n 8 Current employee       370 Research & Development         4\n 9 Current employee       370 Research & Development         4\n10 Current employee       370 Research & Development         4\n# ℹ 23,522 more rows\n```\n:::\n:::\n\n\nThis selects only the *Attrition*, *DailyRate*, *Department*, and *Education* columns.\n\nTo drop specific columns, use the `select()` function with the negation operator `!`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Drop unnecessary columns\ndf <- df %>%\n  select(!c(EmployeeCount, StandardHours, Over18))\n```\n:::\n\n\nThis removes the *EmployeeCount*, *StandardHours*, and *Over18* columns.\n\n### Grouping Data by Variable\n\nGrouping rows is helpful for summarizing data by categories. Here, we’ll group the data by EducationField and count the number of occurrences in each category.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Group by EducationField and count rows\ndf %>%\n  group_by(EducationField) %>%\n  count() %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 × 2\n# Groups:   EducationField [9]\n  EducationField       n\n  <chr>            <int>\n1 Life Sciences     9725\n2 Medical           7393\n3 Marketing         2541\n4 Technical Degree  2105\n5 Other             1311\n6 Human Resources    446\n7 <NA>                 9\n8 3                    1\n9 Test                 1\n```\n:::\n:::\n\n\nThis code:\n\n1.  Groups the data by *EducationField*.\n2.  Counts the rows in each group.\n3.  Arranges the groups in descending order by count (n).\n\n### Recoding Variables\n\nRecoding variables is a common task when transforming categorical data into numerical or more meaningful labels. First, let’s check the frequency of each category in the *Attrition* column:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# View the distribution of Attrition\ntable(df$Attrition)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Current employee           Termination Voluntary Resignation \n                19714                    96                  3709 \n```\n:::\n:::\n\n\nYou can use the `recode()` function from the tidyverse to assign new values to the categories:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recode Attrition variable\ndf$Attrition <- recode(df$Attrition,\n                       \"Current employee\" = 0,\n                       \"Termination\" = 1,\n                       \"Voluntary Resignation\" = 2)\n```\n:::\n\n\nThis transforms Attrition into a numerical variable with the following mapping:\n\n-   0: Current employee\n-   1: Termination\n-   2: Voluntary Resignation\n\n------------------------------------------------------------------------\n\n::: {style=\"display: flex; justify-content: center; align-items: center; height: 100vh;\"}\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/nSRTwoF2Ojnsqy?hostedIn=slideshare&amp;page=upload\" width=\"800\" height=\"600\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## 🎨 Tutorial #2 (Visuals)\n\nWe will use **ggplot2** to create visually appealing scatterplots, apply faceting for multi-panel plots, and customize plots for better presentation. These techniques are essential for exploratory data analysis and communicating insights effectively.\n\n### Scatterplots in ggplot2\n\nScatterplots are a powerful way to visualize relationships between two continuous variables.\n\nHere’s how to create a simple scatterplot of *YearsAtCompany* vs. *TotalWorkingYears* with points colored red:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Basic scatterplot\nggplot(data = df) +\n  geom_point(aes(x = YearsAtCompany, y = TotalWorkingYears), color = \"Red\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThis code plots *YearsAtCompany* on the x-axis and *TotalWorkingYears* on the y-axis with red points.\n\n##### Adding Aesthetic Mappings\n\nTo add another dimension, such as coloring points by *MaritalStatus*, use the `aes()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot with points colored by MaritalStatus\nggplot(data = df) +\n  geom_point(aes(x = YearsAtCompany, y = TotalWorkingYears, color = MaritalStatus))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n<br>\n\n### Faceting for Multi-Panel Plots\n\nFaceting allows you to split the data into panels based on a categorical variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Faceted scatterplot by JobLevel\nggplot(data = df) +\n  geom_point(aes(x = YearsAtCompany, y = YearsInCurrentRole)) +\n  facet_wrap(~JobLevel, nrow = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nThis creates separate scatterplots for each level of JobLevel, arranged in two rows.\n\n<br>\n\n### More Cusomization\n\nFor this section, we’ll use the built-in mpg dataset. To enhance a scatterplot, you can map multiple aesthetics (e.g., color and size), customize axis labels, and add a title:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the dataset\ndata(mpg)\n\n# Scatterplot with multiple aesthetics and customizations\nggplot(mpg, aes(x = displ, y = hwy, color = drv, size = cty)) +\n  geom_point(alpha = 0.7) + # Add points with transparency\n  # Customize axis labels and plot titles\n  labs(title = \"Fuel Efficiency vs. Engine Displacement\",\n       x = \"Engine Displacement (L)\",\n       y = \"Highway MPG\",\n       color = \"Drive Type\",\n       size = \"City MPG\") +\n  # Apply a theme\n  theme_bw() +\n  facet_wrap(~class)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nHere’s what this code does:\n\n-   Aesthetics: Maps drv (drive type) to color and cty (city MPG) to point size.\n-   Labels: Adds a title, and custom axis labels, and modifies the legend titles.\n-   Theme: Applies a clean, white background theme (theme_bw()).\n-   Faceting: Creates facets for each vehicle class.\n\n------------------------------------------------------------------------\n\n::: {style=\"display: flex; justify-content: center; align-items: center; height: 100vh;\"}\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/17ol0GSM7Zvho1?hostedIn=slideshare&amp;page=upload\" width=\"800\" height=\"600\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## 📈 Tutorial #3 (Analysis)\n\n### Summary and Frequency Tables\n\nUse `summary()` and `table()` to calculate basic descriptive statistics and frequency counts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Descriptive statistics for numeric variables\nsummary(df$WorkLifeBalance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   2.000   3.000   2.761   3.000   4.000      10 \n```\n:::\n\n```{.r .cell-code}\n# Frequency table for categorical variables\ntable(df$Gender)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     1      2 Female   Male \n     1      1   9400  14120 \n```\n:::\n:::\n\n\nUsing the `describe` function from the **psych** Package for Detailed Summaries of numeric variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Descriptive statistics for MonthlyIncome\ndescribe(df$MonthlyIncome)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   vars     n    mean      sd median trimmed     mad  min   max range skew\nX1    1 23516 6502.76 4705.99   4936 5666.19 3278.03 1009 19999 18990 1.37\n   kurtosis    se\nX1        1 30.69\n```\n:::\n:::\n\n\n<br>\n\n### t-tests\n\nA t-test is used to compare the means of two groups. Here, we examine differences in *JobSatisfaction* between genders.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filtering Gender\ndf <- df %>%\n  filter(Gender %in% c(\"Female\", \"Male\"))\n\n# Perform t-test\nt.test(df$JobSatisfaction ~ df$Gender, var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  df$JobSatisfaction by df$Gender\nt = -5.0624, df = 23511, p-value = 4.171e-07\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -0.10296313 -0.04548644\nsample estimates:\nmean in group Female   mean in group Male \n            2.681247             2.755472 \n```\n:::\n:::\n\n\n<br>\n\n##### Effect Size\n\nEffect size provides a measure of the magnitude of differences. We calculate Cohen's D using the **lsr** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cohen's D for JobSatisfaction by Gender\ncohensD(df$JobSatisfaction ~ df$Gender)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0674014\n```\n:::\n:::\n\n\n<br>\n\n### One-Way ANOVA\n\nANOVA (Analysis of Variance) is used to compare the means of more than two groups. We analyze *JobSatisfaction* across *Department*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert Department to factor\nclass(df$Department) # Check class\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"character\"\n```\n:::\n\n```{.r .cell-code}\ndf$Department <- as.factor(df$Department) # Convert to factor\n\n# Conduct ANOVA\nanovaTest <- aov(df$JobSatisfaction ~ df$Department)\nsummary(anovaTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Df Sum Sq Mean Sq F value Pr(>F)\ndf$Department     2      1   0.363   0.299  0.742\nResiduals     23499  28524   1.214               \n18 observations deleted due to missingness\n```\n:::\n:::\n\n\n##### Effect Size\n\nafter conducting the ANOVA, we apply Tukey's HSD to compare the *JobSatisfaction* between different levels of *Department*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Post-hoc Tukey's HSD test\nTukeyHSD(anovaTest)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = df$JobSatisfaction ~ df$Department)\n\n$`df$Department`\n                                              diff         lwr        upr\nResearch & Development-Human Resources 0.021787253 -0.06179058 0.10536508\nSales-Human Resources                  0.027838399 -0.05866972 0.11434652\nSales-Research & Development           0.006051146 -0.03093437 0.04303666\n                                           p adj\nResearch & Development-Human Resources 0.8141109\nSales-Human Resources                  0.7310521\nSales-Research & Development           0.9221490\n```\n:::\n:::\n\n\n<br>\n\n### Correlation Analysis\n\nThe correlation between two continuous variables can be calculated using the `cor()` or `cor.test` function. Here, we calculate the correlation between *JobInvolvement* and *RelationshipSatisfaction.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate correlation, using complete observations only\ncor.test(df$JobInvolvement, df$RelationshipSatisfaction, use = \"complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  df$JobInvolvement and df$RelationshipSatisfaction\nt = 5.1325, df = 23506, p-value = 2.882e-07\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.02068330 0.04622137\nsample estimates:\n      cor \n0.0334578 \n```\n:::\n:::\n\n\n<br>\n\n### Multiple Linear Regression\n\nA multiple linear regression model can be used to predict the value of a continuous dependent variable based on multiple independent variables. Here, we build a model predicting *JobSatisfaction*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Multiple linear regression model\nmodel1 <- lm(JobSatisfaction ~ \n              age + Gender + JobLevel + MonthlyIncome, \n            data = df)\n\n# Display the summary of the model\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = JobSatisfaction ~ age + Gender + JobLevel + MonthlyIncome, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0440 -0.7585  0.2526  1.2248  1.4585 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.777e+00  3.336e-02  83.237  < 2e-16 ***\nage           -3.597e-03  8.127e-04  -4.426 9.63e-06 ***\nGenderMale     7.321e-02  1.468e-02   4.989 6.13e-07 ***\nJobLevel       6.273e-02  1.948e-02   3.220  0.00128 ** \nMonthlyIncome -1.412e-05  4.568e-06  -3.090  0.00200 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.101 on 23490 degrees of freedom\n  (25 observations deleted due to missingness)\nMultiple R-squared:  0.002353,\tAdjusted R-squared:  0.002183 \nF-statistic: 13.85 on 4 and 23490 DF,  p-value: 2.77e-11\n```\n:::\n\n```{.r .cell-code}\n# Second model including EducationField as a factor variable\nmodel2 <- lm(JobSatisfaction ~ \n               as.factor(EducationField) + \n               age + Gender + JobLevel + \n               MonthlyIncome, \n             data = df)\n\n# Display the summary of the model\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = JobSatisfaction ~ as.factor(EducationField) + age + \n    Gender + JobLevel + MonthlyIncome, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0400 -0.7611  0.2494  1.2052  1.5089 \n\nCoefficients:\n                                            Estimate Std. Error t value\n(Intercept)                                2.683e+00  6.190e-02  43.347\nas.factor(EducationField)Life Sciences     1.459e-01  5.333e-02   2.735\nas.factor(EducationField)Marketing         8.328e-02  5.653e-02   1.473\nas.factor(EducationField)Medical           5.383e-02  5.370e-02   1.002\nas.factor(EducationField)Other             8.145e-02  6.036e-02   1.350\nas.factor(EducationField)Technical Degree  5.170e-02  5.740e-02   0.901\nas.factor(EducationField)Test              3.908e-01  1.101e+00   0.355\nage                                       -3.670e-03  8.132e-04  -4.513\nGenderMale                                 7.362e-02  1.467e-02   5.018\nJobLevel                                   6.450e-02  1.948e-02   3.311\nMonthlyIncome                             -1.453e-05  4.568e-06  -3.180\n                                          Pr(>|t|)    \n(Intercept)                                < 2e-16 ***\nas.factor(EducationField)Life Sciences    0.006240 ** \nas.factor(EducationField)Marketing        0.140708    \nas.factor(EducationField)Medical          0.316139    \nas.factor(EducationField)Other            0.177169    \nas.factor(EducationField)Technical Degree 0.367754    \nas.factor(EducationField)Test             0.722669    \nage                                       6.42e-06 ***\nGenderMale                                5.27e-07 ***\nJobLevel                                  0.000933 ***\nMonthlyIncome                             0.001472 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.1 on 23477 degrees of freedom\n  (32 observations deleted due to missingness)\nMultiple R-squared:  0.00395,\tAdjusted R-squared:  0.003526 \nF-statistic:  9.31 on 10 and 23477 DF,  p-value: 1.403e-15\n```\n:::\n:::\n\n\n<br>\n\n### Logistic Regression\n\nLogistic regression is used when the dependent variable is binary. We transform Gender into a binary variable and predict it based on *MonthlyIncome* and *JobLevel*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert Gender to binary variable (Male = 1, Female = 0)\ndf <- df %>%\n  mutate(Gender = ifelse(Gender == \"Male\", 1, 0))\n\n# Logistic regression model\nlogit <- glm(Gender ~ MonthlyIncome + JobLevel, data = df, family = \"binomial\")\n\n# Display the summary of the logistic regression model\nsummary(logit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Gender ~ MonthlyIncome + JobLevel, family = \"binomial\", \n    data = df)\n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    5.965e-01  3.214e-02  18.558  < 2e-16 ***\nMonthlyIncome  2.086e-05  8.476e-06   2.461   0.0138 *  \nJobLevel      -1.575e-01  3.611e-02  -4.363 1.28e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 31633  on 23503  degrees of freedom\nResidual deviance: 31589  on 23501  degrees of freedom\n  (16 observations deleted due to missingness)\nAIC: 31595\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# Exponentiate the coefficients to get odds ratios\nexp(coef(logit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) MonthlyIncome      JobLevel \n    1.8157319     1.0000209     0.8542492 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n::: {style=\"display: flex; justify-content: center; align-items: center; height: 100vh;\"}\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/52iNYbcTEtKbEJ?hostedIn=slideshare&amp;page=upload\" width=\"800\" height=\"600\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## 📝 Tutorial #4 (Reports)\n\nWe will use the `apaTables` package to format analysis outputs according to APA guidelines and export them to Word documents.\n\n### APA Style Correlation Table\n\nFirst, we create a correlation matrix using the `cor()` function for a subset of numeric columns from the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Subset of numeric columns for correlation analysis\nnum <- df[, c(\"age\", \"DailyRate\", \"DistanceFromHome\", \n              \"HourlyRate\", \"MonthlyIncome\")]\n\n# Calculate the Pearson correlation matrix\ncorr_matrix <- cor(num, method = \"pearson\", use = \"complete.obs\")\n```\n:::\n\n\nNext, we use the `apa.cor.table()` function from the apaTables package to create a formatted APA-style table.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create and save the APA correlation table\napa.cor.table(corr_matrix, table.number = 1, filename = \"Correlation_table.doc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nTable 1 \n\nMeans, standard deviations, and correlations with confidence intervals\n \n\n  Variable            M    SD   1           2           3           4          \n  1. age              0.25 0.43                                                \n                                                                               \n  2. DailyRate        0.20 0.45 -.30                                           \n                                [-.94, .79]                                    \n                                                                               \n  3. DistanceFromHome 0.20 0.45 -.33        -.27                               \n                                [-.94, .78] [-.93, .80]                        \n                                                                               \n  4. HourlyRate       0.20 0.44 -.35        -.20        -.21                   \n                                [-.94, .77] [-.92, .83] [-.92, .83]            \n                                                                               \n  5. MonthlyIncome    0.24 0.44 .24         -.35        -.32        -.35       \n                                [-.81, .93] [-.94, .77] [-.94, .78] [-.94, .77]\n                                                                               \n\nNote. M and SD are used to represent mean and standard deviation, respectively.\nValues in square brackets indicate the 95% confidence interval.\nThe confidence interval is a plausible range of population correlations \nthat could have caused the sample correlation (Cumming, 2014).\n * indicates p < .05. ** indicates p < .01.\n \n```\n:::\n:::\n\n\nThe above code will generate a Word document with the correlation table in APA format, and the file will be saved as \"Correlation_table.doc\".\n\n<br>\n\n### APA Style ANOVA Table\n\nWe will use the `apa.aov.table()` function to format the ANOVA results into an APA-style table and save it to a Word document.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create and save the APA ANOVA table\napa.aov.table(anovaTest, table.number = 2, filename = \"Anova_table.doc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\nTable 2 \n\nANOVA results using df$JobSatisfaction as the dependent variable\n \n\n     Predictor       SS    df      MS       F    p partial_eta2\n   (Intercept)  7439.59     1 7439.59 6128.95 .000             \n df$Department     0.73     2    0.36    0.30 .742          .00\n         Error 28524.14 23499    1.21                          \n CI_90_partial_eta2\n                   \n         [.00, .00]\n                   \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n```\n:::\n:::\n\n\nThis will generate a Word document containing the APA-formatted ANOVA table, saved as \"Anova_table.doc\".\n\n------------------------------------------------------------------------\n\n::: {style=\"display: flex; justify-content: center; align-items: center; height: 100vh;\"}\n<iframe src=\"https://www.slideshare.net/slideshow/embed_code/key/zQOpFKOflI5hZ?hostedIn=slideshare&amp;page=upload\" width=\"800\" height=\"600\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\">\n\n</iframe>\n:::\n\n## 💭 Conclusion\n\nIn this blog post, we covered key techniques for data manipulation, analysis, and reporting in R. We started with basic operations such as sorting, filtering, and renaming columns using both base R and the dplyr package. We then explored advanced visualization with ggplot2, creating customized scatterplots and faceted plots. The analysis section demonstrated t-tests, ANOVA, regression models, and post-hoc tests to analyze relationships in the data.\n\nWe also learned how to create APA-style tables for correlation matrices and ANOVA results using the apaTables package. While we’ve only scratched the surface of what we can do with R, these tutorials should provide a robust foundation for conducting data analysis in research, business, and academic contexts, while hopefully mitigating initial anxieties associated with learning to code. Happy coding!\n\n## 🔗 Reference\n\nWickham, H., & Grolemund, G. (2017). *R for data science: Import, tidy, transform, visualize, and model data* (1st ed.). O'Reilly Media.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}