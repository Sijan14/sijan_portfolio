---
title: "Projects"
format:
  html:
    embed-resources: true
    allow-raw-html: true
    toc: false
---

### üï∞Ô∏è Delay Discounting as a Latent Factor

<p>[Date:]{style="font-weight: bold;"} December 15, 2024</p>

This project examines the latent factor structure of delay discounting, the tendency to prioritize immediate rewards over delayed ones, which is linked to behavioral outcomes such as substance abuse gambling, credit card debt, and poor academic performance (W√∂lfling et al., 2020). Previous studies have used various methods to measure delay discounting, but the findings have been inconsistent, partly due to differences in operationalization. This study uses confirmatory factor analysis (CFA) to explore the underlying latent factors of delay discounting and their relationship to behavioral outcomes, providing a clearer understanding of the construct and its implications.

<br>

::: {layout-ncol="3"}
::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="project_cfa/one_model.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<p style="font-weight: bold;">

One Factor Model:

</p>

<p>CFI = [.72]{style="color: red;"}</p>

<p>RMSEA = [.24]{style="color: red;"}</p>

<p>SRMR = [.109]{style="color: red;"}</p>

<p>Avg R<sup>2</sup> = [.60]{style="color: green;"}</p>
:::

::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="project_cfa/two_model.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<p style="font-weight: bold;">

Two Factor Model:

</p>

<p>CFI = [.94]{style="color: green;"}</p>

<p>RMSEA = [.12]{style="color: red;"}</p>

<p>SRMR = [.04]{style="color: green;"}</p>

<p>Avg R<sup>2</sup> = [.69]{style="color: green;"}</p>
:::

::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="project_cfa/four_model.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<p style="font-weight: bold;">

Four Factor Model:

</p>

<p>CFI = [.96]{style="color: green;"}</p>

<p>RMSEA = [.10]{style="color: green;"}</p>

<p>SRMR = [.04]{style="color: green;"}</p>

<p>Avg R<sup>2</sup> = [.69]{style="color: green;"}</p>
:::
:::

```{=html}
<style>
  /* CSS for zoom effect on hover */
  .zoom-image {
    transition: transform 0.3s ease-in-out, border 0.3s ease-in-out; /* Added border transition */
  }

  .zoom-image:hover {
    transform: scale(1.1);  /* Adjust the scale factor for zoom level */
    z-index: 10;
    border: 1px solid black;  /* Add black border on hover */
  }
</style>
```
<br>

------------------------------------------------------------------------

### ü§ñ Which ML Algorithms Predict Job Satisfaction The Best?

<p>[Date:]{style="font-weight: bold;"} May 2, 2023</p>

Machine learning algorithms have gained significant popularity in I/O psychology due to their advanced learning capabilities, often outperforming traditional regression methods in predictive tasks. However, their "black-box" nature remains a challenge for research justification. This project compares the performance of baseline model logistic regression with popular algorithms KNN, and random forest in a 4-class job satisfaction classification task using the IBM HR dataset from Kaggle, comprising approximately 23,000 observations. Using lasso-based feature-selection methods, hyperparameter tuning, the project optimizes model performance and identifies the algorithm with the highest predictive accuracy. The findings offer actionable insights into employee well-being, showcasing the potential of data-driven approaches to enhance workforce engagement and organizational performance.

::: {style="display: flex; justify-content: center;"}
```{r, echo=FALSE, warning=FALSE}
suppressMessages(library(plotly))

# Data for the algorithms
data <- data.frame(
  Algorithms = c("LOGIT", "KNN", "KNN (added features)", "KNN (repeated CV)", "Random Forest"),
  Precision = c(0.269, 0.682, 0.938, 0.938, 0.992),
  Sensitivity = c(0.231, 0.690, 0.941, 0.939, 0.994),
  Specificity = c(0.764, 0.897, 0.980, 0.979, 0.998),
  F1_Accuracy = c(0.206, 0.685, 0.939, 0.938, 0.993)
)

# Transform data for Plotly
data_long <- data.frame(
  Algorithms = rep(data$Algorithms, 4),
  Metrics = rep(c("Precision", "Sensitivity", "Specificity", "F1 Accuracy"), each = 5),
  Values = c(data$Precision, data$Sensitivity, data$Specificity, data$F1_Accuracy)
)

# Adjust the order of the metrics
data_long$Metrics <- factor(data_long$Metrics, levels = c("Precision", "Sensitivity", "Specificity", "F1 Accuracy"))

# Create a line plot with hover and dropdown functionality
fig <- plot_ly(
  data_long,
  x = ~Metrics,
  y = ~Values,
  type = 'scatter',
  mode = 'lines+markers',
  color = ~Algorithms,
  hoverinfo = 'text',
  text = ~paste("Algorithm:", Algorithms, "<br>Metric:", Metrics, "<br>Value:", Values)
) %>%
  layout(
    yaxis = list(title = "Value", range = c(0, 1)),
    xaxis = list(title = "Metrics"),
    width = 800,  # Set plot width
    height = 600, # Set plot height
    updatemenus = list(
      list(
        buttons = list(
          list(method = "restyle", args = list("visible", c(TRUE, FALSE, FALSE, FALSE, FALSE)), label = "KNN"),
          list(method = "restyle", args = list("visible", c(FALSE, TRUE, FALSE, FALSE, FALSE)), label = "KNN (added features)"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, TRUE, FALSE, FALSE)), label = "KNN (repeated CV)"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, FALSE, TRUE, FALSE)), label = "LOGIT"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, FALSE, FALSE, TRUE)), label = "Random Forest"),
          list(method = "restyle", args = list("visible", c(TRUE, TRUE, TRUE, TRUE, TRUE)), label = "All Algorithms")
        ),
        direction = "down",
        showactive = TRUE,
        x = 0.8,
        y = 1.2
      )
    )
  )

fig
```
:::

<br>

------------------------------------------------------------------------

### ‚öñÔ∏è Conscientiousness Scale: Development & Validation

<p>[Date:]{style="font-weight: bold;"} April 21, 2023</p>

This project involved the psychometric development of a new Conscientiousness scale, one of the Big Five personality traits. Following best-practice item-writing guidelines, I conducted a pilot study and refined the item pool by removing items with low item-total correlations and minimal impact on Cronbach's alpha if removed (see Figure 1 & 2). Subsequent analyses demonstrated strong internal consistency (Œ± = .91) and validity evidence. The new scale exhibited high convergent validity (r = .85) with the well-validated IPIP Conscientiousness scale and good discriminant validity with other Big Five dimensions (see Figure 3). Criterion validity was supported by a positive correlation with job performance (r = .33), consistent with meta-analytic findings (Sackett et al., 2022), establishing the scale as a valid measure of conscientiousness.

<br>

::: {layout-ncol="3"}
::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="scale_dev/item_total_correlation.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<br>

<p style="font-weight: bold;">

Figure 1

</p>
:::

::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="scale_dev/item_dropped.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<br>

<p style="font-weight: bold;">

Figure 2

</p>
:::

::: {style="text-align:center; border: 1px black; padding: 10px; border-radius: 8px;"}
<img src="scale_dev/construct_validity.png" alt="One Factor Model" class="zoom-image" style="cursor: pointer; max-width: 100%; height: auto;"/>

<br>

<p style="font-weight: bold;">

Figure 3

</p>
:::
:::
