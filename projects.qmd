---
title: "Projects"
format:
  html:
    embed-resources: true
    allow-raw-html: true
    toc: false
---

### Delay Discounting as a Latent Factor

**Date:** December 15, 2024

::: {layout-ncol=3}
<div style="text-align:center; border: 1px solid gray; padding: 10px; border-radius: 8px;">
  <a href="cfa_project/of_model.png" target="_blank">
    <img src="cfa_project/of_model.png" alt="One Factor Model" style="cursor: pointer; max-width: 100%; height: auto;">
  </a>
  <p><strong>One Factor Model:</strong></p>
  <p>CFI = <span style="color: red;">.72</span></p>
  <p>RMSEA = <span style="color: red;">.24</span></p>
  <p>SRMR = <span style="color: red;">.109</span></p>
  <p>Avg R<sup>2</sup> = <span style="color: green;">.60</span></p>
</div>

<div style="text-align:center; border: 1px solid gray; padding: 10px; border-radius: 8px;">
  <a href="cfa_project/tf_model.png" target="_blank">
    <img src="cfa_project/tf_model.png" alt="Two Factor Model" style="cursor: pointer; max-width: 100%; height: auto;">
  </a>
  <p><strong>Two Factor Model:</strong></p>
  <p>CFI = <span style="color: green;">.94</span></p>
  <p>RMSEA = <span style="color: red;">.12</span></p>
  <p>SRMR = <span style="color: green;">.04</span></p>
  <p>Avg R<sup>2</sup> = <span style="color: green;">.69</span></p>
</div>

<div style="text-align:center; border: 1px solid gray; padding: 10px; border-radius: 8px;">
  <a href="cfa_project/ff_model.png" target="_blank">
    <img src="cfa_project/ff_model.png" alt="Four Factor Model" style="cursor: pointer; max-width: 100%; height: auto;">
  </a>
  <p><strong>Four Factor Model:</strong></p>
  <p>CFI = <span style="color: green;">.96</span></p>
  <p>RMSEA = <span style="color: green;">.10</span></p>
  <p>SRMR = <span style="color: green;">.04</span></p>
  <p>Avg R<sup>2</sup> = <span style="color: green;">.69</span></p>
</div>
:::


### Which ML Algorithms Predict Job Satisfaction The Best?

**Date:** May 2, 2023

Machine learning algorithms have gained significant popularity in I/O psychology due to their advanced learning capabilities, often outperforming traditional regression methods in predictive tasks. However, their "black-box" nature remains a challenge for research justification. This project compares the performance of baseline model logistic regression with popular algorithms KNN, and random forest in a 4-class job satisfaction classification task using the IBM HR dataset from Kaggle, comprising approximately 23,000 observations. Using lasso-based feature-selection methods, hyperparameter tuning, the project optimizes model performance and identifies the algorithm with the highest predictive accuracy. The findings offer actionable insights into employee well-being, showcasing the potential of data-driven approaches to enhance workforce engagement and organizational performance.

::: {style="display: flex; justify-content: center;"}
```{r, echo=FALSE, warning=FALSE}
suppressMessages(library(plotly))

# Data for the algorithms
data <- data.frame(
  Algorithms = c("LOGIT", "KNN", "KNN (added features)", "KNN (repeated CV)", "Random Forest"),
  Precision = c(0.269, 0.682, 0.938, 0.938, 0.992),
  Sensitivity = c(0.231, 0.690, 0.941, 0.939, 0.994),
  Specificity = c(0.764, 0.897, 0.980, 0.979, 0.998),
  F1_Accuracy = c(0.206, 0.685, 0.939, 0.938, 0.993)
)

# Transform data for Plotly
data_long <- data.frame(
  Algorithms = rep(data$Algorithms, 4),
  Metrics = rep(c("Precision", "Sensitivity", "Specificity", "F1 Accuracy"), each = 5),
  Values = c(data$Precision, data$Sensitivity, data$Specificity, data$F1_Accuracy)
)

# Adjust the order of the metrics
data_long$Metrics <- factor(data_long$Metrics, levels = c("Precision", "Sensitivity", "Specificity", "F1 Accuracy"))

# Create a line plot with hover and dropdown functionality
fig <- plot_ly(
  data_long,
  x = ~Metrics,
  y = ~Values,
  type = 'scatter',
  mode = 'lines+markers',
  color = ~Algorithms,
  hoverinfo = 'text',
  text = ~paste("Algorithm:", Algorithms, "<br>Metric:", Metrics, "<br>Value:", Values)
) %>%
  layout(
    yaxis = list(title = "Value", range = c(0, 1)),
    xaxis = list(title = "Metrics"),
    width = 800,  # Set plot width
    height = 600, # Set plot height
    updatemenus = list(
      list(
        buttons = list(
          list(method = "restyle", args = list("visible", c(TRUE, FALSE, FALSE, FALSE, FALSE)), label = "KNN"),
          list(method = "restyle", args = list("visible", c(FALSE, TRUE, FALSE, FALSE, FALSE)), label = "KNN (added features)"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, TRUE, FALSE, FALSE)), label = "KNN (repeated CV)"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, FALSE, TRUE, FALSE)), label = "LOGIT"),
          list(method = "restyle", args = list("visible", c(FALSE, FALSE, FALSE, FALSE, TRUE)), label = "Random Forest"),
          list(method = "restyle", args = list("visible", c(TRUE, TRUE, TRUE, TRUE, TRUE)), label = "All Algorithms")
        ),
        direction = "down",
        showactive = TRUE,
        x = 0.8,
        y = 1.2
      )
    )
  )

fig
```
:::
